{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_2_sequence_model_Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschlup/csck507_team_a/blob/main/seq2seq%20from%20tutorial%20-%20adapted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Translation using a RNN\n",
        "\n",
        "In this tutorial we will learn how to RNNs to build Sequence-2-Sequence (seq-2-seq) model for Neural machine Translation. We will build LSTM-based seq-2-seq model for translating German sentences into English sentences. "
      ],
      "metadata": {
        "id": "Yb_n81X5rsmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us import the necessary libraries\n",
        "\n",
        "1. Pytorch for using LSTM layer\n",
        "2. Spacy for text processing"
      ],
      "metadata": {
        "id": "GySNhZA2rjLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtM2tDZIrR29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.de import German\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from tqdm import tqdm_notebook\n",
        "import random\n",
        "from collections import Counter\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVHLHDXRCDu2",
        "outputId": "042d82a0-03a0-4b8e-a833-4c684c053714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: No such file or directory\n",
            "/bin/bash: google-drive-ocamlfuse: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sGbmmS1ujKS",
        "outputId": "d77a105e-030c-4f9d-c71a-95f403607977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"/content/gdrive/Shareddrives/Colab_Notebooks/CSCK507/W6_Seq2SeqTutorial_Data/\""
      ],
      "metadata": {
        "id": "u74b4FDJ8tpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file \"data/deu.txt\" (in the data folder) consists of parallel sentences in French and English, which we will use to train our seq-2-seq model. The function \"prepare_data\" process the data file to obtain token representions required for the seq-2-seq model."
      ],
      "metadata": {
        "id": "DaNzaCUe4n7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(root_path, file_name, train_samples):\n",
        "  # Reading the English-German sentences pairs from the file\n",
        "  with open(root_path+file_name, \"r+\", encoding='utf-8') as file:\n",
        "    deu = [x[:-1] for x in file.readlines()]\n",
        "  en = []\n",
        "  de = []\n",
        "  # get english/french sentence pairs\n",
        "  for line in deu:\n",
        "    en.append(line.split(\"\\t\")[0])\n",
        "    de.append(line.split(\"\\t\")[1])\n",
        "  \n",
        "    # Setting the number of training sentences we'll use\n",
        "  training_examples = train_samples\n",
        "  # We'll be using the spaCy's English and German tokenizers\n",
        "  spacy_en = English()\n",
        "  spacy_de = German()\n",
        "  \n",
        "  en_words = Counter()\n",
        "  de_words = Counter()\n",
        "  en_inputs = []\n",
        "  de_inputs = []\n",
        "  \n",
        "  # Tokenizing the English and German sentences and creating our word banks for both languages\n",
        "  for i in range(training_examples):\n",
        "      en_tokens = spacy_en(en[i])\n",
        "      de_tokens = spacy_de(de[i])\n",
        "      if len(en_tokens)==0 or len(de_tokens)==0:\n",
        "          continue\n",
        "      for token in en_tokens:\n",
        "          en_words.update([token.text.lower()])\n",
        "      en_inputs.append([token.text.lower() for token in en_tokens] + ['_EOS'])\n",
        "      for token in de_tokens:\n",
        "          de_words.update([token.text.lower()])\n",
        "      de_inputs.append([token.text.lower() for token in de_tokens] + ['_EOS'])\n",
        "    \n",
        "  # Assigning an index to each word token, including the Start Of String(SOS), End Of String(EOS) and Unknown(UNK) tokens\n",
        "  en_words = ['_SOS','_EOS','_UNK'] + sorted(en_words,key=en_words.get,reverse=True)\n",
        "  en_w2i = {o:i for i,o in enumerate(en_words)}\n",
        "  en_i2w = {i:o for i,o in enumerate(en_words)}\n",
        "  de_words = ['_SOS','_EOS','_UNK'] + sorted(de_words,key=de_words.get,reverse=True)\n",
        "  de_w2i = {o:i for i,o in enumerate(de_words)}\n",
        "  de_i2w = {i:o for i,o in enumerate(de_words)}\n",
        "  \n",
        "  # Converting our English and German sentences to their token indexes\n",
        "  for i in range(len(en_inputs)):\n",
        "      en_sentence = en_inputs[i]\n",
        "      de_sentence = de_inputs[i]\n",
        "      en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
        "      de_inputs[i] = [de_w2i[word] for word in de_sentence]\n",
        "  \n",
        "  return en_words, de_words, en_w2i, en_i2w, de_w2i, de_i2w, en_inputs, de_inputs\n"
      ],
      "metadata": {
        "id": "1HYjRSY78tgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_words, de_words, en_w2i, en_i2w, de_w2i, de_i2w, en_inputs, de_inputs = prepare_data(root_path, \"data/deu.txt\", 10000)\n",
        "\n",
        "en_inputs[0], de_inputs[0]"
      ],
      "metadata": {
        "id": "Fljz0IuY-qNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e69b2b-31fb-4296-e5dc-3cb2ca0735c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([22, 3, 1], [65, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write our Encoder Class"
      ],
      "metadata": {
        "id": "Y9WWqnNO6Jap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, vocab_len, input_dim, hidden_dim, n_layers=1, drop_prob=0):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        " \n",
        "    self.embedding = nn.Embedding(vocab_len, input_dim)\n",
        "    self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, \n",
        "                        dropout=drop_prob, batch_first=True)\n",
        " \n",
        "  def forward(self, inputs, encoder_state_vector, encoder_cell_vector):\n",
        "    embedded = self.embedding(inputs)\n",
        "    # Pass the embedded word vectors into LSTM and return all outputs\n",
        "    output, hidden = self.lstm(embedded, (encoder_state_vector, encoder_cell_vector))\n",
        "    return output, hidden\n",
        " \n",
        "  def init_hidden(self, batch_size=1):\n",
        "    return (torch.zeros(self.n_layers, batch_size, \n",
        "                        self.hidden_dim),\n",
        "            torch.zeros(self.n_layers, batch_size, \n",
        "                        self.hidden_dim))\n"
      ],
      "metadata": {
        "id": "uUiYFmormj2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write our Decoder class"
      ],
      "metadata": {
        "id": "ounElB9y8FuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_vocab_len, n_layers=1, drop_prob=0.1):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_vocab_len = output_vocab_len\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_prob = drop_prob\n",
        "    self.input_dim = input_dim\n",
        " \n",
        "    self.embedding = nn.Embedding(self.output_vocab_len, self.input_dim)\n",
        "    self.dropout = nn.Dropout(self.drop_prob) \n",
        "    self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, batch_first=True)\n",
        "    self.classifier = nn.Linear(self.hidden_dim, self.output_vocab_len)\n",
        "\n",
        "  def forward(self, inputs, decoder_state_vector, decoder_context_vector):\n",
        "    # Embed input words\n",
        "    embedded = self.embedding(inputs).view(1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "    embedded = embedded.unsqueeze(0)\n",
        "    \n",
        "    output, hidden = self.lstm(embedded, (decoder_state_vector, \n",
        "                                          decoder_context_vector))\n",
        "\n",
        "    # Pass LSTM outputs through a Linear layer acting as a classifier\n",
        "    output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
        "\n",
        "    return output, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "syV2C9IY_WN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train our model and save the trained model to the \"model\" directory."
      ],
      "metadata": {
        "id": "ufgTe0by6khT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 100\n",
        "hidden_dim = 256\n",
        "\n",
        "encoder = EncoderLSTM(len(en_words), input_dim, hidden_dim)\n",
        "decoder = DecoderLSTM(input_dim, hidden_dim, len(de_words))\n",
        " \n",
        "lr = 0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
        "\n",
        "EPOCHS = 10\n",
        "teacher_forcing_prob = 0.5\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "tk0 = range(1,EPOCHS+1)\n",
        "for epoch in tk0:\n",
        "    avg_loss = 0.\n",
        "    tk1 = enumerate(en_inputs)\n",
        "\n",
        "    for i, sentence in tk1:\n",
        "\n",
        "        loss = 0.\n",
        "\n",
        "        #initialise encoder state vector and cell state vector\n",
        "        h = encoder.init_hidden()\n",
        "        encoder_state_vector = h[0]\n",
        "        encoder_cell_vector = h[0]\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        inp = torch.tensor(sentence).unsqueeze(0)\n",
        "\n",
        "        #print('inp: ', epoch, inp)\n",
        "        if (i % 100) == 0:\n",
        "          print('inp: ', i, epoch)\n",
        "        encoder_outputs, h = encoder(inp, encoder_state_vector, encoder_cell_vector)\n",
        "        \n",
        "        #First decoder input will be the SOS token\n",
        "        decoder_input = torch.tensor([en_w2i['_SOS']])\n",
        "        #First decoder hidden state will be last encoder hidden state\n",
        "        decoder_hidden = h\n",
        "\n",
        "        output = []\n",
        "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
        "\n",
        "        for ii in range(len(de_inputs[i])):\n",
        "          decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden[0], decoder_hidden[1])\n",
        "\n",
        "          # Get the index value of the word with the highest score from the decoder output\n",
        "          top_value, top_index = decoder_output.topk(1)\n",
        "          if teacher_forcing:\n",
        "            decoder_input = torch.tensor([de_inputs[i][ii]])\n",
        "          else:\n",
        "            decoder_input = torch.tensor([top_index.item()])\n",
        "            \n",
        "          output.append(top_index.item())\n",
        "          # Calculate the loss of the prediction against the actual word\n",
        "          loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([de_inputs[i][ii]]))\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        avg_loss += loss.item()/len(en_inputs)\n",
        "    print(avg_loss)\n",
        "\n",
        "# Save model after every epoch (Optional)\n",
        "torch.save({\"encoder\":encoder.state_dict(),\"decoder\":decoder.state_dict(),\"e_optimizer\":encoder_optimizer.state_dict(),\"d_optimizer\":decoder_optimizer},root_path+\"model/model_enc_dec.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqttxnJ2_qBS",
        "outputId": "c7da4786-c7ae-4ec3-fd3b-ec65a8477067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp:  0 1\n",
            "inp:  100 1\n",
            "inp:  200 1\n",
            "inp:  300 1\n",
            "inp:  400 1\n",
            "inp:  500 1\n",
            "inp:  600 1\n",
            "inp:  700 1\n",
            "inp:  800 1\n",
            "inp:  900 1\n",
            "inp:  1000 1\n",
            "inp:  1100 1\n",
            "inp:  1200 1\n",
            "inp:  1300 1\n",
            "inp:  1400 1\n",
            "inp:  1500 1\n",
            "inp:  1600 1\n",
            "inp:  1700 1\n",
            "inp:  1800 1\n",
            "inp:  1900 1\n",
            "inp:  2000 1\n",
            "inp:  2100 1\n",
            "inp:  2200 1\n",
            "inp:  2300 1\n",
            "inp:  2400 1\n",
            "inp:  2500 1\n",
            "inp:  2600 1\n",
            "inp:  2700 1\n",
            "inp:  2800 1\n",
            "inp:  2900 1\n",
            "inp:  3000 1\n",
            "inp:  3100 1\n",
            "inp:  3200 1\n",
            "inp:  3300 1\n",
            "inp:  3400 1\n",
            "inp:  3500 1\n",
            "inp:  3600 1\n",
            "inp:  3700 1\n",
            "inp:  3800 1\n",
            "inp:  3900 1\n",
            "inp:  4000 1\n",
            "inp:  4100 1\n",
            "inp:  4200 1\n",
            "inp:  4300 1\n",
            "inp:  4400 1\n",
            "inp:  4500 1\n",
            "inp:  4600 1\n",
            "inp:  4700 1\n",
            "inp:  4800 1\n",
            "inp:  4900 1\n",
            "inp:  5000 1\n",
            "inp:  5100 1\n",
            "inp:  5200 1\n",
            "inp:  5300 1\n",
            "inp:  5400 1\n",
            "inp:  5500 1\n",
            "inp:  5600 1\n",
            "inp:  5700 1\n",
            "inp:  5800 1\n",
            "inp:  5900 1\n",
            "inp:  6000 1\n",
            "inp:  6100 1\n",
            "inp:  6200 1\n",
            "inp:  6300 1\n",
            "inp:  6400 1\n",
            "inp:  6500 1\n",
            "inp:  6600 1\n",
            "inp:  6700 1\n",
            "inp:  6800 1\n",
            "inp:  6900 1\n",
            "inp:  7000 1\n",
            "inp:  7100 1\n",
            "inp:  7200 1\n",
            "inp:  7300 1\n",
            "inp:  7400 1\n",
            "inp:  7500 1\n",
            "inp:  7600 1\n",
            "inp:  7700 1\n",
            "inp:  7800 1\n",
            "inp:  7900 1\n",
            "inp:  8000 1\n",
            "inp:  8100 1\n",
            "inp:  8200 1\n",
            "inp:  8300 1\n",
            "inp:  8400 1\n",
            "inp:  8500 1\n",
            "inp:  8600 1\n",
            "inp:  8700 1\n",
            "inp:  8800 1\n",
            "inp:  8900 1\n",
            "inp:  9000 1\n",
            "inp:  9100 1\n",
            "inp:  9200 1\n",
            "inp:  9300 1\n",
            "inp:  9400 1\n",
            "inp:  9500 1\n",
            "inp:  9600 1\n",
            "inp:  9700 1\n",
            "inp:  9800 1\n",
            "inp:  9900 1\n",
            "18.2140169869185\n",
            "inp:  0 2\n",
            "inp:  100 2\n",
            "inp:  200 2\n",
            "inp:  300 2\n",
            "inp:  400 2\n",
            "inp:  500 2\n",
            "inp:  600 2\n",
            "inp:  700 2\n",
            "inp:  800 2\n",
            "inp:  900 2\n",
            "inp:  1000 2\n",
            "inp:  1100 2\n",
            "inp:  1200 2\n",
            "inp:  1300 2\n",
            "inp:  1400 2\n",
            "inp:  1500 2\n",
            "inp:  1600 2\n",
            "inp:  1700 2\n",
            "inp:  1800 2\n",
            "inp:  1900 2\n",
            "inp:  2000 2\n",
            "inp:  2100 2\n",
            "inp:  2200 2\n",
            "inp:  2300 2\n",
            "inp:  2400 2\n",
            "inp:  2500 2\n",
            "inp:  2600 2\n",
            "inp:  2700 2\n",
            "inp:  2800 2\n",
            "inp:  2900 2\n",
            "inp:  3000 2\n",
            "inp:  3100 2\n",
            "inp:  3200 2\n",
            "inp:  3300 2\n",
            "inp:  3400 2\n",
            "inp:  3500 2\n",
            "inp:  3600 2\n",
            "inp:  3700 2\n",
            "inp:  3800 2\n",
            "inp:  3900 2\n",
            "inp:  4000 2\n",
            "inp:  4100 2\n",
            "inp:  4200 2\n",
            "inp:  4300 2\n",
            "inp:  4400 2\n",
            "inp:  4500 2\n",
            "inp:  4600 2\n",
            "inp:  4700 2\n",
            "inp:  4800 2\n",
            "inp:  4900 2\n",
            "inp:  5000 2\n",
            "inp:  5100 2\n",
            "inp:  5200 2\n",
            "inp:  5300 2\n",
            "inp:  5400 2\n",
            "inp:  5500 2\n",
            "inp:  5600 2\n",
            "inp:  5700 2\n",
            "inp:  5800 2\n",
            "inp:  5900 2\n",
            "inp:  6000 2\n",
            "inp:  6100 2\n",
            "inp:  6200 2\n",
            "inp:  6300 2\n",
            "inp:  6400 2\n",
            "inp:  6500 2\n",
            "inp:  6600 2\n",
            "inp:  6700 2\n",
            "inp:  6800 2\n",
            "inp:  6900 2\n",
            "inp:  7000 2\n",
            "inp:  7100 2\n",
            "inp:  7200 2\n",
            "inp:  7300 2\n",
            "inp:  7400 2\n",
            "inp:  7500 2\n",
            "inp:  7600 2\n",
            "inp:  7700 2\n",
            "inp:  7800 2\n",
            "inp:  7900 2\n",
            "inp:  8000 2\n",
            "inp:  8100 2\n",
            "inp:  8200 2\n",
            "inp:  8300 2\n",
            "inp:  8400 2\n",
            "inp:  8500 2\n",
            "inp:  8600 2\n",
            "inp:  8700 2\n",
            "inp:  8800 2\n",
            "inp:  8900 2\n",
            "inp:  9000 2\n",
            "inp:  9100 2\n",
            "inp:  9200 2\n",
            "inp:  9300 2\n",
            "inp:  9400 2\n",
            "inp:  9500 2\n",
            "inp:  9600 2\n",
            "inp:  9700 2\n",
            "inp:  9800 2\n",
            "inp:  9900 2\n",
            "13.347904795980414\n",
            "inp:  0 3\n",
            "inp:  100 3\n",
            "inp:  200 3\n",
            "inp:  300 3\n",
            "inp:  400 3\n",
            "inp:  500 3\n",
            "inp:  600 3\n",
            "inp:  700 3\n",
            "inp:  800 3\n",
            "inp:  900 3\n",
            "inp:  1000 3\n",
            "inp:  1100 3\n",
            "inp:  1200 3\n",
            "inp:  1300 3\n",
            "inp:  1400 3\n",
            "inp:  1500 3\n",
            "inp:  1600 3\n",
            "inp:  1700 3\n",
            "inp:  1800 3\n",
            "inp:  1900 3\n",
            "inp:  2000 3\n",
            "inp:  2100 3\n",
            "inp:  2200 3\n",
            "inp:  2300 3\n",
            "inp:  2400 3\n",
            "inp:  2500 3\n",
            "inp:  2600 3\n",
            "inp:  2700 3\n",
            "inp:  2800 3\n",
            "inp:  2900 3\n",
            "inp:  3000 3\n",
            "inp:  3100 3\n",
            "inp:  3200 3\n",
            "inp:  3300 3\n",
            "inp:  3400 3\n",
            "inp:  3500 3\n",
            "inp:  3600 3\n",
            "inp:  3700 3\n",
            "inp:  3800 3\n",
            "inp:  3900 3\n",
            "inp:  4000 3\n",
            "inp:  4100 3\n",
            "inp:  4200 3\n",
            "inp:  4300 3\n",
            "inp:  4400 3\n",
            "inp:  4500 3\n",
            "inp:  4600 3\n",
            "inp:  4700 3\n",
            "inp:  4800 3\n",
            "inp:  4900 3\n",
            "inp:  5000 3\n",
            "inp:  5100 3\n",
            "inp:  5200 3\n",
            "inp:  5300 3\n",
            "inp:  5400 3\n",
            "inp:  5500 3\n",
            "inp:  5600 3\n",
            "inp:  5700 3\n",
            "inp:  5800 3\n",
            "inp:  5900 3\n",
            "inp:  6000 3\n",
            "inp:  6100 3\n",
            "inp:  6200 3\n",
            "inp:  6300 3\n",
            "inp:  6400 3\n",
            "inp:  6500 3\n",
            "inp:  6600 3\n",
            "inp:  6700 3\n",
            "inp:  6800 3\n",
            "inp:  6900 3\n",
            "inp:  7000 3\n",
            "inp:  7100 3\n",
            "inp:  7200 3\n",
            "inp:  7300 3\n",
            "inp:  7400 3\n",
            "inp:  7500 3\n",
            "inp:  7600 3\n",
            "inp:  7700 3\n",
            "inp:  7800 3\n",
            "inp:  7900 3\n",
            "inp:  8000 3\n",
            "inp:  8100 3\n",
            "inp:  8200 3\n",
            "inp:  8300 3\n",
            "inp:  8400 3\n",
            "inp:  8500 3\n",
            "inp:  8600 3\n",
            "inp:  8700 3\n",
            "inp:  8800 3\n",
            "inp:  8900 3\n",
            "inp:  9000 3\n",
            "inp:  9100 3\n",
            "inp:  9200 3\n",
            "inp:  9300 3\n",
            "inp:  9400 3\n",
            "inp:  9500 3\n",
            "inp:  9600 3\n",
            "inp:  9700 3\n",
            "inp:  9800 3\n",
            "inp:  9900 3\n",
            "10.594297216501852\n",
            "inp:  0 4\n",
            "inp:  100 4\n",
            "inp:  200 4\n",
            "inp:  300 4\n",
            "inp:  400 4\n",
            "inp:  500 4\n",
            "inp:  600 4\n",
            "inp:  700 4\n",
            "inp:  800 4\n",
            "inp:  900 4\n",
            "inp:  1000 4\n",
            "inp:  1100 4\n",
            "inp:  1200 4\n",
            "inp:  1300 4\n",
            "inp:  1400 4\n",
            "inp:  1500 4\n",
            "inp:  1600 4\n",
            "inp:  1700 4\n",
            "inp:  1800 4\n",
            "inp:  1900 4\n",
            "inp:  2000 4\n",
            "inp:  2100 4\n",
            "inp:  2200 4\n",
            "inp:  2300 4\n",
            "inp:  2400 4\n",
            "inp:  2500 4\n",
            "inp:  2600 4\n",
            "inp:  2700 4\n",
            "inp:  2800 4\n",
            "inp:  2900 4\n",
            "inp:  3000 4\n",
            "inp:  3100 4\n",
            "inp:  3200 4\n",
            "inp:  3300 4\n",
            "inp:  3400 4\n",
            "inp:  3500 4\n",
            "inp:  3600 4\n",
            "inp:  3700 4\n",
            "inp:  3800 4\n",
            "inp:  3900 4\n",
            "inp:  4000 4\n",
            "inp:  4100 4\n",
            "inp:  4200 4\n",
            "inp:  4300 4\n",
            "inp:  4400 4\n",
            "inp:  4500 4\n",
            "inp:  4600 4\n",
            "inp:  4700 4\n",
            "inp:  4800 4\n",
            "inp:  4900 4\n",
            "inp:  5000 4\n",
            "inp:  5100 4\n",
            "inp:  5200 4\n",
            "inp:  5300 4\n",
            "inp:  5400 4\n",
            "inp:  5500 4\n",
            "inp:  5600 4\n",
            "inp:  5700 4\n",
            "inp:  5800 4\n",
            "inp:  5900 4\n",
            "inp:  6000 4\n",
            "inp:  6100 4\n",
            "inp:  6200 4\n",
            "inp:  6300 4\n",
            "inp:  6400 4\n",
            "inp:  6500 4\n",
            "inp:  6600 4\n",
            "inp:  6700 4\n",
            "inp:  6800 4\n",
            "inp:  6900 4\n",
            "inp:  7000 4\n",
            "inp:  7100 4\n",
            "inp:  7200 4\n",
            "inp:  7300 4\n",
            "inp:  7400 4\n",
            "inp:  7500 4\n",
            "inp:  7600 4\n",
            "inp:  7700 4\n",
            "inp:  7800 4\n",
            "inp:  7900 4\n",
            "inp:  8000 4\n",
            "inp:  8100 4\n",
            "inp:  8200 4\n",
            "inp:  8300 4\n",
            "inp:  8400 4\n",
            "inp:  8500 4\n",
            "inp:  8600 4\n",
            "inp:  8700 4\n",
            "inp:  8800 4\n",
            "inp:  8900 4\n",
            "inp:  9000 4\n",
            "inp:  9100 4\n",
            "inp:  9200 4\n",
            "inp:  9300 4\n",
            "inp:  9400 4\n",
            "inp:  9500 4\n",
            "inp:  9600 4\n",
            "inp:  9700 4\n",
            "inp:  9800 4\n",
            "inp:  9900 4\n",
            "8.341796349327273\n",
            "inp:  0 5\n",
            "inp:  100 5\n",
            "inp:  200 5\n",
            "inp:  300 5\n",
            "inp:  400 5\n",
            "inp:  500 5\n",
            "inp:  600 5\n",
            "inp:  700 5\n",
            "inp:  800 5\n",
            "inp:  900 5\n",
            "inp:  1000 5\n",
            "inp:  1100 5\n",
            "inp:  1200 5\n",
            "inp:  1300 5\n",
            "inp:  1400 5\n",
            "inp:  1500 5\n",
            "inp:  1600 5\n",
            "inp:  1700 5\n",
            "inp:  1800 5\n",
            "inp:  1900 5\n",
            "inp:  2000 5\n",
            "inp:  2100 5\n",
            "inp:  2200 5\n",
            "inp:  2300 5\n",
            "inp:  2400 5\n",
            "inp:  2500 5\n",
            "inp:  2600 5\n",
            "inp:  2700 5\n",
            "inp:  2800 5\n",
            "inp:  2900 5\n",
            "inp:  3000 5\n",
            "inp:  3100 5\n",
            "inp:  3200 5\n",
            "inp:  3300 5\n",
            "inp:  3400 5\n",
            "inp:  3500 5\n",
            "inp:  3600 5\n",
            "inp:  3700 5\n",
            "inp:  3800 5\n",
            "inp:  3900 5\n",
            "inp:  4000 5\n",
            "inp:  4100 5\n",
            "inp:  4200 5\n",
            "inp:  4300 5\n",
            "inp:  4400 5\n",
            "inp:  4500 5\n",
            "inp:  4600 5\n",
            "inp:  4700 5\n",
            "inp:  4800 5\n",
            "inp:  4900 5\n",
            "inp:  5000 5\n",
            "inp:  5100 5\n",
            "inp:  5200 5\n",
            "inp:  5300 5\n",
            "inp:  5400 5\n",
            "inp:  5500 5\n",
            "inp:  5600 5\n",
            "inp:  5700 5\n",
            "inp:  5800 5\n",
            "inp:  5900 5\n",
            "inp:  6000 5\n",
            "inp:  6100 5\n",
            "inp:  6200 5\n",
            "inp:  6300 5\n",
            "inp:  6400 5\n",
            "inp:  6500 5\n",
            "inp:  6600 5\n",
            "inp:  6700 5\n",
            "inp:  6800 5\n",
            "inp:  6900 5\n",
            "inp:  7000 5\n",
            "inp:  7100 5\n",
            "inp:  7200 5\n",
            "inp:  7300 5\n",
            "inp:  7400 5\n",
            "inp:  7500 5\n",
            "inp:  7600 5\n",
            "inp:  7700 5\n",
            "inp:  7800 5\n",
            "inp:  7900 5\n",
            "inp:  8000 5\n",
            "inp:  8100 5\n",
            "inp:  8200 5\n",
            "inp:  8300 5\n",
            "inp:  8400 5\n",
            "inp:  8500 5\n",
            "inp:  8600 5\n",
            "inp:  8700 5\n",
            "inp:  8800 5\n",
            "inp:  8900 5\n",
            "inp:  9000 5\n",
            "inp:  9100 5\n",
            "inp:  9200 5\n",
            "inp:  9300 5\n",
            "inp:  9400 5\n",
            "inp:  9500 5\n",
            "inp:  9600 5\n",
            "inp:  9700 5\n",
            "inp:  9800 5\n",
            "inp:  9900 5\n",
            "6.609124959363045\n",
            "inp:  0 6\n",
            "inp:  100 6\n",
            "inp:  200 6\n",
            "inp:  300 6\n",
            "inp:  400 6\n",
            "inp:  500 6\n",
            "inp:  600 6\n",
            "inp:  700 6\n",
            "inp:  800 6\n",
            "inp:  900 6\n",
            "inp:  1000 6\n",
            "inp:  1100 6\n",
            "inp:  1200 6\n",
            "inp:  1300 6\n",
            "inp:  1400 6\n",
            "inp:  1500 6\n",
            "inp:  1600 6\n",
            "inp:  1700 6\n",
            "inp:  1800 6\n",
            "inp:  1900 6\n",
            "inp:  2000 6\n",
            "inp:  2100 6\n",
            "inp:  2200 6\n",
            "inp:  2300 6\n",
            "inp:  2400 6\n",
            "inp:  2500 6\n",
            "inp:  2600 6\n",
            "inp:  2700 6\n",
            "inp:  2800 6\n",
            "inp:  2900 6\n",
            "inp:  3000 6\n",
            "inp:  3100 6\n",
            "inp:  3200 6\n",
            "inp:  3300 6\n",
            "inp:  3400 6\n",
            "inp:  3500 6\n",
            "inp:  3600 6\n",
            "inp:  3700 6\n",
            "inp:  3800 6\n",
            "inp:  3900 6\n",
            "inp:  4000 6\n",
            "inp:  4100 6\n",
            "inp:  4200 6\n",
            "inp:  4300 6\n",
            "inp:  4400 6\n",
            "inp:  4500 6\n",
            "inp:  4600 6\n",
            "inp:  4700 6\n",
            "inp:  4800 6\n",
            "inp:  4900 6\n",
            "inp:  5000 6\n",
            "inp:  5100 6\n",
            "inp:  5200 6\n",
            "inp:  5300 6\n",
            "inp:  5400 6\n",
            "inp:  5500 6\n",
            "inp:  5600 6\n",
            "inp:  5700 6\n",
            "inp:  5800 6\n",
            "inp:  5900 6\n",
            "inp:  6000 6\n",
            "inp:  6100 6\n",
            "inp:  6200 6\n",
            "inp:  6300 6\n",
            "inp:  6400 6\n",
            "inp:  6500 6\n",
            "inp:  6600 6\n",
            "inp:  6700 6\n",
            "inp:  6800 6\n",
            "inp:  6900 6\n",
            "inp:  7000 6\n",
            "inp:  7100 6\n",
            "inp:  7200 6\n",
            "inp:  7300 6\n",
            "inp:  7400 6\n",
            "inp:  7500 6\n",
            "inp:  7600 6\n",
            "inp:  7700 6\n",
            "inp:  7800 6\n",
            "inp:  7900 6\n",
            "inp:  8000 6\n",
            "inp:  8100 6\n",
            "inp:  8200 6\n",
            "inp:  8300 6\n",
            "inp:  8400 6\n",
            "inp:  8500 6\n",
            "inp:  8600 6\n",
            "inp:  8700 6\n",
            "inp:  8800 6\n",
            "inp:  8900 6\n",
            "inp:  9000 6\n",
            "inp:  9100 6\n",
            "inp:  9200 6\n",
            "inp:  9300 6\n",
            "inp:  9400 6\n",
            "inp:  9500 6\n",
            "inp:  9600 6\n",
            "inp:  9700 6\n",
            "inp:  9800 6\n",
            "inp:  9900 6\n",
            "5.318335680368539\n",
            "inp:  0 7\n",
            "inp:  100 7\n",
            "inp:  200 7\n",
            "inp:  300 7\n",
            "inp:  400 7\n",
            "inp:  500 7\n",
            "inp:  600 7\n",
            "inp:  700 7\n",
            "inp:  800 7\n",
            "inp:  900 7\n",
            "inp:  1000 7\n",
            "inp:  1100 7\n",
            "inp:  1200 7\n",
            "inp:  1300 7\n",
            "inp:  1400 7\n",
            "inp:  1500 7\n",
            "inp:  1600 7\n",
            "inp:  1700 7\n",
            "inp:  1800 7\n",
            "inp:  1900 7\n",
            "inp:  2000 7\n",
            "inp:  2100 7\n",
            "inp:  2200 7\n",
            "inp:  2300 7\n",
            "inp:  2400 7\n",
            "inp:  2500 7\n",
            "inp:  2600 7\n",
            "inp:  2700 7\n",
            "inp:  2800 7\n",
            "inp:  2900 7\n",
            "inp:  3000 7\n",
            "inp:  3100 7\n",
            "inp:  3200 7\n",
            "inp:  3300 7\n",
            "inp:  3400 7\n",
            "inp:  3500 7\n",
            "inp:  3600 7\n",
            "inp:  3700 7\n",
            "inp:  3800 7\n",
            "inp:  3900 7\n",
            "inp:  4000 7\n",
            "inp:  4100 7\n",
            "inp:  4200 7\n",
            "inp:  4300 7\n",
            "inp:  4400 7\n",
            "inp:  4500 7\n",
            "inp:  4600 7\n",
            "inp:  4700 7\n",
            "inp:  4800 7\n",
            "inp:  4900 7\n",
            "inp:  5000 7\n",
            "inp:  5100 7\n",
            "inp:  5200 7\n",
            "inp:  5300 7\n",
            "inp:  5400 7\n",
            "inp:  5500 7\n",
            "inp:  5600 7\n",
            "inp:  5700 7\n",
            "inp:  5800 7\n",
            "inp:  5900 7\n",
            "inp:  6000 7\n",
            "inp:  6100 7\n",
            "inp:  6200 7\n",
            "inp:  6300 7\n",
            "inp:  6400 7\n",
            "inp:  6500 7\n",
            "inp:  6600 7\n",
            "inp:  6700 7\n",
            "inp:  6800 7\n",
            "inp:  6900 7\n",
            "inp:  7000 7\n",
            "inp:  7100 7\n",
            "inp:  7200 7\n",
            "inp:  7300 7\n",
            "inp:  7400 7\n",
            "inp:  7500 7\n",
            "inp:  7600 7\n",
            "inp:  7700 7\n",
            "inp:  7800 7\n",
            "inp:  7900 7\n",
            "inp:  8000 7\n",
            "inp:  8100 7\n",
            "inp:  8200 7\n",
            "inp:  8300 7\n",
            "inp:  8400 7\n",
            "inp:  8500 7\n",
            "inp:  8600 7\n",
            "inp:  8700 7\n",
            "inp:  8800 7\n",
            "inp:  8900 7\n",
            "inp:  9000 7\n",
            "inp:  9100 7\n",
            "inp:  9200 7\n",
            "inp:  9300 7\n",
            "inp:  9400 7\n",
            "inp:  9500 7\n",
            "inp:  9600 7\n",
            "inp:  9700 7\n",
            "inp:  9800 7\n",
            "inp:  9900 7\n",
            "4.430549749986335\n",
            "inp:  0 8\n",
            "inp:  100 8\n",
            "inp:  200 8\n",
            "inp:  300 8\n",
            "inp:  400 8\n",
            "inp:  500 8\n",
            "inp:  600 8\n",
            "inp:  700 8\n",
            "inp:  800 8\n",
            "inp:  900 8\n",
            "inp:  1000 8\n",
            "inp:  1100 8\n",
            "inp:  1200 8\n",
            "inp:  1300 8\n",
            "inp:  1400 8\n",
            "inp:  1500 8\n",
            "inp:  1600 8\n",
            "inp:  1700 8\n",
            "inp:  1800 8\n",
            "inp:  1900 8\n",
            "inp:  2000 8\n",
            "inp:  2100 8\n",
            "inp:  2200 8\n",
            "inp:  2300 8\n",
            "inp:  2400 8\n",
            "inp:  2500 8\n",
            "inp:  2600 8\n",
            "inp:  2700 8\n",
            "inp:  2800 8\n",
            "inp:  2900 8\n",
            "inp:  3000 8\n",
            "inp:  3100 8\n",
            "inp:  3200 8\n",
            "inp:  3300 8\n",
            "inp:  3400 8\n",
            "inp:  3500 8\n",
            "inp:  3600 8\n",
            "inp:  3700 8\n",
            "inp:  3800 8\n",
            "inp:  3900 8\n",
            "inp:  4000 8\n",
            "inp:  4100 8\n",
            "inp:  4200 8\n",
            "inp:  4300 8\n",
            "inp:  4400 8\n",
            "inp:  4500 8\n",
            "inp:  4600 8\n",
            "inp:  4700 8\n",
            "inp:  4800 8\n",
            "inp:  4900 8\n",
            "inp:  5000 8\n",
            "inp:  5100 8\n",
            "inp:  5200 8\n",
            "inp:  5300 8\n",
            "inp:  5400 8\n",
            "inp:  5500 8\n",
            "inp:  5600 8\n",
            "inp:  5700 8\n",
            "inp:  5800 8\n",
            "inp:  5900 8\n",
            "inp:  6000 8\n",
            "inp:  6100 8\n",
            "inp:  6200 8\n",
            "inp:  6300 8\n",
            "inp:  6400 8\n",
            "inp:  6500 8\n",
            "inp:  6600 8\n",
            "inp:  6700 8\n",
            "inp:  6800 8\n",
            "inp:  6900 8\n",
            "inp:  7000 8\n",
            "inp:  7100 8\n",
            "inp:  7200 8\n",
            "inp:  7300 8\n",
            "inp:  7400 8\n",
            "inp:  7500 8\n",
            "inp:  7600 8\n",
            "inp:  7700 8\n",
            "inp:  7800 8\n",
            "inp:  7900 8\n",
            "inp:  8000 8\n",
            "inp:  8100 8\n",
            "inp:  8200 8\n",
            "inp:  8300 8\n",
            "inp:  8400 8\n",
            "inp:  8500 8\n",
            "inp:  8600 8\n",
            "inp:  8700 8\n",
            "inp:  8800 8\n",
            "inp:  8900 8\n",
            "inp:  9000 8\n",
            "inp:  9100 8\n",
            "inp:  9200 8\n",
            "inp:  9300 8\n",
            "inp:  9400 8\n",
            "inp:  9500 8\n",
            "inp:  9600 8\n",
            "inp:  9700 8\n",
            "inp:  9800 8\n",
            "inp:  9900 8\n",
            "3.881196321988656\n",
            "inp:  0 9\n",
            "inp:  100 9\n",
            "inp:  200 9\n",
            "inp:  300 9\n",
            "inp:  400 9\n",
            "inp:  500 9\n",
            "inp:  600 9\n",
            "inp:  700 9\n",
            "inp:  800 9\n",
            "inp:  900 9\n",
            "inp:  1000 9\n",
            "inp:  1100 9\n",
            "inp:  1200 9\n",
            "inp:  1300 9\n",
            "inp:  1400 9\n",
            "inp:  1500 9\n",
            "inp:  1600 9\n",
            "inp:  1700 9\n",
            "inp:  1800 9\n",
            "inp:  1900 9\n",
            "inp:  2000 9\n",
            "inp:  2100 9\n",
            "inp:  2200 9\n",
            "inp:  2300 9\n",
            "inp:  2400 9\n",
            "inp:  2500 9\n",
            "inp:  2600 9\n",
            "inp:  2700 9\n",
            "inp:  2800 9\n",
            "inp:  2900 9\n",
            "inp:  3000 9\n",
            "inp:  3100 9\n",
            "inp:  3200 9\n",
            "inp:  3300 9\n",
            "inp:  3400 9\n",
            "inp:  3500 9\n",
            "inp:  3600 9\n",
            "inp:  3700 9\n",
            "inp:  3800 9\n",
            "inp:  3900 9\n",
            "inp:  4000 9\n",
            "inp:  4100 9\n",
            "inp:  4200 9\n",
            "inp:  4300 9\n",
            "inp:  4400 9\n",
            "inp:  4500 9\n",
            "inp:  4600 9\n",
            "inp:  4700 9\n",
            "inp:  4800 9\n",
            "inp:  4900 9\n",
            "inp:  5000 9\n",
            "inp:  5100 9\n",
            "inp:  5200 9\n",
            "inp:  5300 9\n",
            "inp:  5400 9\n",
            "inp:  5500 9\n",
            "inp:  5600 9\n",
            "inp:  5700 9\n",
            "inp:  5800 9\n",
            "inp:  5900 9\n",
            "inp:  6000 9\n",
            "inp:  6100 9\n",
            "inp:  6200 9\n",
            "inp:  6300 9\n",
            "inp:  6400 9\n",
            "inp:  6500 9\n",
            "inp:  6600 9\n",
            "inp:  6700 9\n",
            "inp:  6800 9\n",
            "inp:  6900 9\n",
            "inp:  7000 9\n",
            "inp:  7100 9\n",
            "inp:  7200 9\n",
            "inp:  7300 9\n",
            "inp:  7400 9\n",
            "inp:  7500 9\n",
            "inp:  7600 9\n",
            "inp:  7700 9\n",
            "inp:  7800 9\n",
            "inp:  7900 9\n",
            "inp:  8000 9\n",
            "inp:  8100 9\n",
            "inp:  8200 9\n",
            "inp:  8300 9\n",
            "inp:  8400 9\n",
            "inp:  8500 9\n",
            "inp:  8600 9\n",
            "inp:  8700 9\n",
            "inp:  8800 9\n",
            "inp:  8900 9\n",
            "inp:  9000 9\n",
            "inp:  9100 9\n",
            "inp:  9200 9\n",
            "inp:  9300 9\n",
            "inp:  9400 9\n",
            "inp:  9500 9\n",
            "inp:  9600 9\n",
            "inp:  9700 9\n",
            "inp:  9800 9\n",
            "inp:  9900 9\n",
            "3.4593935661892283\n",
            "inp:  0 10\n",
            "inp:  100 10\n",
            "inp:  200 10\n",
            "inp:  300 10\n",
            "inp:  400 10\n",
            "inp:  500 10\n",
            "inp:  600 10\n",
            "inp:  700 10\n",
            "inp:  800 10\n",
            "inp:  900 10\n",
            "inp:  1000 10\n",
            "inp:  1100 10\n",
            "inp:  1200 10\n",
            "inp:  1300 10\n",
            "inp:  1400 10\n",
            "inp:  1500 10\n",
            "inp:  1600 10\n",
            "inp:  1700 10\n",
            "inp:  1800 10\n",
            "inp:  1900 10\n",
            "inp:  2000 10\n",
            "inp:  2100 10\n",
            "inp:  2200 10\n",
            "inp:  2300 10\n",
            "inp:  2400 10\n",
            "inp:  2500 10\n",
            "inp:  2600 10\n",
            "inp:  2700 10\n",
            "inp:  2800 10\n",
            "inp:  2900 10\n",
            "inp:  3000 10\n",
            "inp:  3100 10\n",
            "inp:  3200 10\n",
            "inp:  3300 10\n",
            "inp:  3400 10\n",
            "inp:  3500 10\n",
            "inp:  3600 10\n",
            "inp:  3700 10\n",
            "inp:  3800 10\n",
            "inp:  3900 10\n",
            "inp:  4000 10\n",
            "inp:  4100 10\n",
            "inp:  4200 10\n",
            "inp:  4300 10\n",
            "inp:  4400 10\n",
            "inp:  4500 10\n",
            "inp:  4600 10\n",
            "inp:  4700 10\n",
            "inp:  4800 10\n",
            "inp:  4900 10\n",
            "inp:  5000 10\n",
            "inp:  5100 10\n",
            "inp:  5200 10\n",
            "inp:  5300 10\n",
            "inp:  5400 10\n",
            "inp:  5500 10\n",
            "inp:  5600 10\n",
            "inp:  5700 10\n",
            "inp:  5800 10\n",
            "inp:  5900 10\n",
            "inp:  6000 10\n",
            "inp:  6100 10\n",
            "inp:  6200 10\n",
            "inp:  6300 10\n",
            "inp:  6400 10\n",
            "inp:  6500 10\n",
            "inp:  6600 10\n",
            "inp:  6700 10\n",
            "inp:  6800 10\n",
            "inp:  6900 10\n",
            "inp:  7000 10\n",
            "inp:  7100 10\n",
            "inp:  7200 10\n",
            "inp:  7300 10\n",
            "inp:  7400 10\n",
            "inp:  7500 10\n",
            "inp:  7600 10\n",
            "inp:  7700 10\n",
            "inp:  7800 10\n",
            "inp:  7900 10\n",
            "inp:  8000 10\n",
            "inp:  8100 10\n",
            "inp:  8200 10\n",
            "inp:  8300 10\n",
            "inp:  8400 10\n",
            "inp:  8500 10\n",
            "inp:  8600 10\n",
            "inp:  8700 10\n",
            "inp:  8800 10\n",
            "inp:  8900 10\n",
            "inp:  9000 10\n",
            "inp:  9100 10\n",
            "inp:  9200 10\n",
            "inp:  9300 10\n",
            "inp:  9400 10\n",
            "inp:  9500 10\n",
            "inp:  9600 10\n",
            "inp:  9700 10\n",
            "inp:  9800 10\n",
            "inp:  9900 10\n",
            "3.2415114105032012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the pretrained model to check translation for some random sentences in the corpus."
      ],
      "metadata": {
        "id": "C8rbwSCMKOx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(root_path+\"model/model_enc_dec.pt\")\n",
        "\n",
        "encoder.load_state_dict(checkpoint['encoder'])\n",
        "decoder.load_state_dict(checkpoint['decoder'])\n",
        "encoder_optimizer.load_state_dict(checkpoint['e_optimizer'])\n",
        "#decoder_optimizer.load_state_dict(checkpoint['d_optimizer'])\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# get some random numbers to choose random sentences\n",
        "rand_integers = [random.randint(0, 10000) for i in range(1, 20)]\n",
        "\n",
        "for i in rand_integers:\n",
        "  h = encoder.init_hidden()\n",
        "  inp = torch.tensor(en_inputs[i]).unsqueeze(0)\n",
        "  encoder_outputs, h = encoder(inp, h[0], h[1])\n",
        "   \n",
        "  decoder_input = torch.tensor([en_w2i['_SOS']])\n",
        "  decoder_hidden = h\n",
        "  output = []\n",
        "  attentions = []\n",
        "  while True:\n",
        "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden[0], decoder_hidden[1])\n",
        "    _, top_index = decoder_output.topk(1)\n",
        "    decoder_input = torch.tensor([top_index.item()])\n",
        "    # If the decoder output is the End Of Sentence token, stop decoding process\n",
        "    if top_index.item() == de_w2i[\"_EOS\"]:\n",
        "      break\n",
        "    output.append(top_index.item())\n",
        "  \n",
        "  print(\"English: \"+ \" \".join([en_i2w[x] for x in en_inputs[i]]))\n",
        "  print(\"Predicted: \" + \" \".join([de_i2w[x] for x in output]))\n",
        "  print(\"Actual: \" + \" \".join([de_i2w[x] for x in de_inputs[i]]))\n",
        "  print()\n",
        "   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ufbdIyUwzE-",
        "outputId": "053842f5-cc2d-4256-d2ab-823769e49d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: i want a lot . _EOS\n",
            "Predicted: ich möchte viel .\n",
            "Actual: ich möchte viel . _EOS\n",
            "\n",
            "English: life is unfair . _EOS\n",
            "Predicted: das leben ist unfair .\n",
            "Actual: das leben ist unfair . _EOS\n",
            "\n",
            "English: tom broke it . _EOS\n",
            "Predicted: tom hat es ruiniert . gegeben .\n",
            "Actual: tom hat es kaputt gemacht . _EOS\n",
            "\n",
            "English: you can rest . _EOS\n",
            "Predicted: du können dich ausruhen .\n",
            "Actual: du kannst ausruhen . _EOS\n",
            "\n",
            "English: is it a deer ? _EOS\n",
            "Predicted: ist es ein geheimnis ?\n",
            "Actual: ist es ein hirsch ? _EOS\n",
            "\n",
            "English: take tom . _EOS\n",
            "Predicted: nimm tom um .\n",
            "Actual: nimm tom . _EOS\n",
            "\n",
            "English: you 're lost . _EOS\n",
            "Predicted: ihr habt euch verirrt .\n",
            "Actual: du hast dich verirrt . _EOS\n",
            "\n",
            "English: life is fun . _EOS\n",
            "Predicted: das leben macht spaß .\n",
            "Actual: das leben macht spaß . _EOS\n",
            "\n",
            "English: i like women . _EOS\n",
            "Predicted: ich mag gern .\n",
            "Actual: ich mag frauen . _EOS\n",
            "\n",
            "English: i know my job . _EOS\n",
            "Predicted: ich kenne mich in meinem beruf .\n",
            "Actual: ich kenne mich in meinem beruf aus . _EOS\n",
            "\n",
            "English: i feel stupid . _EOS\n",
            "Predicted: ich fühle mich dumm .\n",
            "Actual: ich fühle mich dumm . _EOS\n",
            "\n",
            "English: can we ask tom ? _EOS\n",
            "Predicted: können wir tom fragen ?\n",
            "Actual: können wir tom fragen ? _EOS\n",
            "\n",
            "English: good for you . _EOS\n",
            "Predicted: schön für dich .\n",
            "Actual: schön für dich . _EOS\n",
            "\n",
            "English: he sells cars . _EOS\n",
            "Predicted: er verkauft autos .\n",
            "Actual: er verkauft autos . _EOS\n",
            "\n",
            "English: is it strange ? _EOS\n",
            "Predicted: ist es komisch ?\n",
            "Actual: ist das komisch ? _EOS\n",
            "\n",
            "English: i feel dizzy . _EOS\n",
            "Predicted: mir ist schwindelig .\n",
            "Actual: mir ist schwindelig . _EOS\n",
            "\n",
            "English: is that a dog ? _EOS\n",
            "Predicted: ist das ein hund hund ?\n",
            "Actual: ist das dort ein hund ? _EOS\n",
            "\n",
            "English: i changed . _EOS\n",
            "Predicted: ich ändere mich .\n",
            "Actual: ich änderte mich . _EOS\n",
            "\n",
            "English: i 'm diabetic . _EOS\n",
            "Predicted: ich bin diabetiker .\n",
            "Actual: ich bin diabetiker . _EOS\n",
            "\n"
          ]
        }
      ]
    }
  ]
}