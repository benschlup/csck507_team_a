{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCK507_Team_A_ChatBot_ONE.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/benschlup/csck507_team_a/blob/main/CSCK507_Team_A_ChatBot_THREE.ipynb",
      "authorship_tag": "ABX9TyOvF33lhri3ONWsXTlWMyu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschlup/csck507_team_a/blob/main/CSCK507_Team_A_ChatBot_THREE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSCK507 Natural Language Processing\n",
        "## Team A"
      ],
      "metadata": {
        "id": "dXeItkpo51bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspired by https://medium.com/swlh/how-to-design-seq2seq-chatbot-using-keras-framework-ae86d950e91d\n",
        "\n",
        "Additional interesting materials to review, and potentially reference:\n",
        "Khin, N.N., Soe, K.M., 2020. Question Answering based University Chatbot using Sequence to Sequence Model, in: .. doi:10.1109/o-cocosda50338.2020.9295021\n",
        "\n"
      ],
      "metadata": {
        "id": "kv0kmUiLmJSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import codecs\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import yaml\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
      ],
      "metadata": {
        "id": "CmdlY3dO1O_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the GPU is visible to our runtime\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "metadata": {
        "id": "B9cNSuwm07wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what GPU we have in place\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ijf1uMKAXnbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "urllib.request.urlretrieve(\"https://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\", \"Question_Answer_Dataset_v1.2.tar.gz\")"
      ],
      "metadata": {
        "id": "mYkrBnyV1L-E",
        "outputId": "ecb1e4ff-22ee-40eb-bb7b-6a770c9f93e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Question_Answer_Dataset_v1.2.tar.gz',\n",
              " <http.client.HTTPMessage at 0x7f5fddc6fd90>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files\n",
        "file = tarfile.open('Question_Answer_Dataset_v1.2.tar.gz')\n",
        "file.extractall('.')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "d09_-PN51ois"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import questions and answers from all courses in Spring 2008, 2009 and 2010 respectively\n",
        "qa_df = pd.DataFrame()\n",
        "for course in ['S08', 'S09', 'S10']:\n",
        "    print(f'Reading questions and answers from course {course}')\n",
        "    course_qa_df = pd.read_csv( f'./Question_Answer_Dataset_v1.2/{course}/question_answer_pairs.txt', sep='\\t', encoding='ISO-8859-1')\n",
        "    course_qa_df['course'] = course\n",
        "    qa_df = pd.concat([qa_df, course_qa_df])\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "e_tpDQAUEiKK",
        "outputId": "7b2eec80-635b-4a72-c143-c7bb136069f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading questions and answers from course S08\n",
            "Reading questions and answers from course S09\n",
            "Reading questions and answers from course S10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove lines not having answers (or not even having questions, in some cases...):\n",
        "qa_df = qa_df[qa_df['Answer'].notna()]"
      ],
      "metadata": {
        "id": "RY7VF6eGNUbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove duplicates\n",
        "## Add the length of the answer to the dataframe\n",
        "#qa_df['answer_length'] = qa_df['Answer'].str.len()\n",
        "## Sort the dataframe to have the longest answer per question at the top\n",
        "#qa_df.sort_values(['Question', 'answer_length'], inplace=True)\n",
        "## Remove duplicated questions, retaining only the longest answer\n",
        "#qa_df.drop_duplicates(subset=['Question'], keep='last', inplace=True)\n"
      ],
      "metadata": {
        "id": "z8aXSVNSP-zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive normalized questions\n",
        "qa_df['norm_question'] = [ re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", s).lower() for s in qa_df['Question'] ]\n",
        "\n",
        "# Answers are no harder\n",
        "qa_df['norm_answer'] = [ '_START_ '+re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", s).lower() for s in qa_df['Answer']+' _STOP_' ]"
      ],
      "metadata": {
        "id": "QQ1553hGYQL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set-up model\n",
        "\n",
        "# Filter for tokenizer:\n",
        "# Reconsider adding numbers to filter later, as encoding of numbers may create excessive vocabulary\n",
        "# Check reference https://arxiv.org/abs/2103.13136\n",
        "target_regex = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\'' \n",
        "tokenizer = Tokenizer(filters=target_regex)\n",
        "tokenizer.fit_on_texts(qa_df['norm_question'] + qa_df['norm_answer'])\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "tokenized_questions = tokenizer.texts_to_sequences(qa_df['norm_question'])\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "encoder_input_data = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "print(f'Encoder input data shape: {encoder_input_data.shape})')\n",
        "\n",
        "tokenized_answers = tokenizer.texts_to_sequences(qa_df['norm_answer'])\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "decoder_input_data = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "print(decoder_input_data.shape)\n",
        "\n",
        "#for i in range(len(tokenized_answers)):\n",
        "#    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "tokenized_answers = [ ta[1:] for ta in tokenized_answers]\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "decoder_output_data = to_categorical(padded_answers, VOCAB_SIZE)\n",
        "\n",
        "print(decoder_output_data.shape)\n",
        "\n",
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(enc_inputs)\n",
        "_, state_h, state_c = LSTM(200, return_state=True)(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(dec_inputs)\n",
        "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "dec_dense = Dense(VOCAB_SIZE, activation=softmax)\n",
        "output = dec_dense(dec_outputs)\n",
        "\n",
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZedlpHo6-62P",
        "outputId": "96137d29-f997-4042-cc58-1eb128f0dcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input data shape: (3422, 44))\n",
            "(3422, 158)\n",
            "(3422, 158, 5701)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    1140200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1140200     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 5701)   1145901     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,067,901\n",
            "Trainable params: 4,067,901\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_output_data, batch_size=50, epochs=100)\n",
        "#model.save('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glC5E6w1M9mk",
        "outputId": "18173b57-44ef-4101-ea0f-0f5d83f86a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 13s 72ms/step - loss: 0.2126\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.1750\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1665\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1596\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1539\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1488\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1444\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1402\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1362\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1323\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1289\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1253\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1218\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1183\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1147\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1115\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.1080\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1047\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.1015\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0979\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0946\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0913\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0879\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0847\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0816\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 5s 70ms/step - loss: 0.0783\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0752\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0722\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0692\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0663\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0636\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0609\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0582\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0555\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0533\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0504\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0486\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 5s 75ms/step - loss: 0.0459\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0435\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0413\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0392\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0373\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0352\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0333\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0314\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0299\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0280\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0266\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0249\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0236\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0222\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0210\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0196\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0184\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0173\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0163\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0153\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0144\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0136\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0127\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0120\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0114\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 5s 74ms/step - loss: 0.0107\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0102\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0096\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0091\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0086\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0082\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0077\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0074\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0070\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0067\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0064\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0062\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0058\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0056\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 5s 70ms/step - loss: 0.0054\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0052\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0050\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0048\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0046\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0045\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0044\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0042\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0041\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0040\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0040\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0038\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 5s 75ms/step - loss: 0.0037\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0037\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0036\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0035\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0034\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0034\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0033\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0033\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0032\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 5s 72ms/step - loss: 0.0032\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 5s 71ms/step - loss: 0.0032\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 5s 73ms/step - loss: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare models for inferencing (separate encoder, decoder)\n",
        "#model.load_weights('/content/drive/MyDrive/CSCK507_Team_A/qa_model.h5')\n",
        "\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = Input(shape=(200,))\n",
        "    dec_state_input_c = Input(shape=(200,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                             initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    print('Inference encoder:')\n",
        "    enc_model.summary()\n",
        "    return enc_model, dec_model\n",
        "\n",
        "\n",
        "# Also here: need to change to lemmas in case we do that on training data\n",
        "# (see above)\n",
        "# Furthermore, there'd be a more compact way of expressing\n",
        "# below code... but for simplicity, taken from example for time being\n",
        "def str_to_tokens(sentence):\n",
        "    words = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", sentence).lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')\n",
        "\n",
        "\n",
        "enc_model, dec_model = make_inference_models()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHYIs3pL86Ov",
        "outputId": "7eaec081-cb7b-4040-c1e9-c91f557d0e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    1140200     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'input_9[0][0]',                \n",
            "                                 (None, 200)]                     'input_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 5701)   1145901     ['lstm_1[4][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,606,901\n",
            "Trainable params: 2,606,901\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 200)         1140200   \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 200),             320800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461,000\n",
            "Trainable params: 1,461,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get 100 random numbers to choose random sentences and calculate BLEU score\n",
        "# note that code must be refactored: it was merged from examples and is \n",
        "# inconsistent now\n",
        "questions = qa_df['Question'].to_list()\n",
        "rand_integers = [random.randint(0, len(questions)-1) for i in range(1, 100)]\n",
        "bleu_total = 0\n",
        "\n",
        "\n",
        "for i in rand_integers:\n",
        "    states_values = enc_model.predict(str_to_tokens(questions[i]))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    decoded_translation = decoded_translation[1:]\n",
        "\n",
        "    print(f'Original question: {questions[i]}')\n",
        "    print(f'Predicated answer: {decoded_translation}')\n",
        "\n",
        "    reference_answers = qa_df.loc[qa_df['Question']==questions[i], 'norm_answer'].to_list()\n",
        "    reference_answers = [answer[8:-7] for answer in reference_answers]\n",
        "\n",
        "\n",
        "    # The following should contain all possible answers, though...\n",
        "    print(f'{reference_answers}')\n",
        "    bleu_score = sentence_bleu(reference_answers, decoded_translation, smoothing_function=SmoothingFunction().method0)\n",
        "    print(f'Bleu score: {bleu_score}\\n')\n",
        "    bleu_total += bleu_score\n",
        "\n",
        "print(f'Bleu average = {bleu_total/len(rand_integers)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QObKQwyVLNzY",
        "outputId": "8abe3117-a25c-4648-fb25-7d7db259fba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original question: Are all spoken varieties of Chinese tonal and analytical?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did Tesla win the Nobel Prize?\n",
            "Predicated answer: no\n",
            "['no']\n",
            "Bleu score: 1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original question: Who did Newton see as the master creator?\n",
            "Predicated answer: god\n",
            "['god', 'newton saw god as the master creator whose existence could not be denied in the face of the grandeur of all creation']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was faraday `s  earliest  chemical  work as an assistant  to Davy?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are drums often used in music therapy?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What may happen to red fire ants if we use boiling water on the queen?\n",
            "Predicated answer: nests of red fire ants may be destroyed\n",
            "['nests of red fire ants may be destroyed', 'die']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is Taipei in a valley?\n",
            "Predicated answer: yes\n",
            "['taipei is in the valleys of the keelung and xindian rivers', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did he become chief engineer in the Department of Bridges and Highways in 1892?\n",
            "Predicated answer: no\n",
            "['no', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Who left Verroccio's studio?\n",
            "Predicated answer: leonardo is radioactivity\n",
            "[\"leonardo da vinci left verroccio's studio\"]\n",
            "Bleu score: 0.24099812828603165\n",
            "\n",
            "Original question: Was Tesla rich at the time of his death?\n",
            "Predicated answer: no\n",
            "['no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did Wilson's father own slaves?\n",
            "Predicated answer: yes\n",
            "['yes', 'yeah']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How many parts of speech does the Korean language contain?\n",
            "Predicated answer: the korean language contains nine parts of speech\n",
            "['the korean language contains nine parts of speech ']\n",
            "Bleu score: 0.9797986738537043\n",
            "\n",
            "Original question: Who was Avogadro's wife?\n",
            "Predicated answer: maple mazzé was from avogadro s law\n",
            "['felicita mazz', \"felicita mazzé was avogadro's wife\"]\n",
            "Bleu score: 0.5447422018643453\n",
            "\n",
            "Original question: Is there an airport in Liechtenstein?\n",
            "Predicated answer: no\n",
            "['no', 'no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is the largest ethnic minority in Romania?\n",
            "Predicated answer: hungarians\n",
            "['hungarians', 'hungarians']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are cymbals used in moden orchestras?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How many people did the 1970 Bhola cyclone kill?\n",
            "Predicated answer: 500000\n",
            "['500000']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are there at least two films describing Tesla 's life ?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Do women live longer than men?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is it true that he sent in federal troops to chicago?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where did Charles-Augustin de Coulomb die?\n",
            "Predicated answer: charlesaugustin de coulomb died in paris\n",
            "['charlesaugustin de coulomb died in paris', 'paris france']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Have plains zebras been crossed with mountain zebras?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did the Moche people worship lobsters?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are beetles endopterygotes?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did the modern hi-hat evolve from clash cymbals?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is modern Korean written in columns or rows?\n",
            "Predicated answer: it is written in rows\n",
            "['it is written in rows']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Regarding this topic, what did Antonio Stradivari do?\n",
            "Predicated answer: antonio stradivari made violins\n",
            "['antonio stradivari made violins']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Which two sports events did the Olympiastadion host?\n",
            "Predicated answer: the olympiastadion hosted the 1936 summer olympics and the 2006 fifa world cup final\n",
            "['the olympiastadion hosted the 1936 summer olympics and the 2006 fifa world cup final ', 'the 1936 summer olympics and the 2006 fifa world cup final']\n",
            "Bleu score: 0.9881658194110153\n",
            "\n",
            "Original question: How do turtles reproduce?\n",
            "Predicated answer: they lay eggs\n",
            "['they lay eggs', 'they lay eggs']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What makes a trumpet fully chromatic?\n",
            "Predicated answer: able to play all twelve pitches of western music\n",
            "['able to play all twelve pitches of western music']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where was the deepest note of the classical lyre in relation to the player's body?\n",
            "Predicated answer: it was farthest from the player s body\n",
            "[\"it was farthest from the player's body\"]\n",
            "Bleu score: 0.9299238452109287\n",
            "\n",
            "Original question: What is the name of a university (or similar institution for imparting higher education) in Beijing?\n",
            "Predicated answer: tsinghua university\n",
            "['tsinghua university']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How do turtles chew food?\n",
            "Predicated answer: turtles use their jaws to cut and chew food\n",
            "['turtles use their jaws to cut and chew food', 'turtles use their jaws to cut and chew food']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When did Canada have one of the largest armed forces in the world?\n",
            "Predicated answer: 1944\n",
            "['1944', 'world war ii']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where are there craters named Becquerel?\n",
            "Predicated answer: on the moon and on mars\n",
            "['moon and mars', 'on the moon and on mars']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Has the flute been dated to prehistoric times?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did John Adams represent the Continental Congress in Europe?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Do all ducks \"quack\"?\n",
            "Predicated answer: no\n",
            "['no', 'no', 'no', 'no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was Fillmore the first U.S. President born after the death of a former president ?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When did the first verifiable written documents appear?\n",
            "Predicated answer: the first verifiable written documents appeared in the twelfth century\n",
            "['twelfth century', ' the first verifiable written documents appeared in the twelfth century ']\n",
            "Bleu score: 0.9718328750329812\n",
            "\n",
            "Original question: Was Isaac Newton educated at The King's Schol, Grantham?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was Adams an opponent of the Stamp Act?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is Finland's economy like?\n",
            "Predicated answer: a doctrine of it s swan of this with this\n",
            "['a highly industrialised freemarket economy']\n",
            "Bleu score: 0.23077450962753568\n",
            "\n",
            "Original question: What are Carleton University's athletic teams called?\n",
            "Predicated answer: to instrument\n",
            "['carleton ravens']\n",
            "Bleu score: 0.5369787816169341\n",
            "\n",
            "Original question: What information did he record in his diary?\n",
            "Predicated answer: descriptions of events and ompressions of men\n",
            "['descriptions of events and ompressions of men', 'he wrote descriptions of events and impressions of men']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: With what party did Adams run for presidency?\n",
            "Predicated answer: the federalist party\n",
            "['the federalist party', 'the federalist party']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where is Michael Faraday buried?\n",
            "Predicated answer: in the dissenters section of highgate cemetery\n",
            "[\"michael faraday is buried in the dissenters' section of highgate cemetery\", \"in the dissenters' section of highgate cemetery\"]\n",
            "Bleu score: 0.949851806476473\n",
            "\n",
            "Original question: Was Isaac Newton educated at The King's Schol, Grantham?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When did written Vietnamese become the official administrative language?\n",
            "Predicated answer: the 20th century\n",
            "['the 20th century', 'vietnamese became the official administrative language by the 20th century']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When was Charles-Augustin de Coulomb permanently stationed in Paris?\n",
            "Predicated answer: yes\n",
            "['charlesaugustin de coulomb was permanently stationed in paris in 1781', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Which temperature scale did Celsius propose?\n",
            "Predicated answer: the celsius temperature scale\n",
            "['celcius', ' the celsius temperature scale ']\n",
            "Bleu score: 0.9333588643117228\n",
            "\n",
            "Original question: Do other landmarks include the Istiqlal Mosque as well as Jakarta Cathedral?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did Ulysses win the Battle of Champion Hill?\n",
            "Predicated answer: yes\n",
            "['yes', 'you betcha']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Do giraffes give birth standing up?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is Uruguay very common?\n",
            "Predicated answer: no\n",
            "['no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How many state parks are in San Francisco?\n",
            "Predicated answer: there is only one park managed by the california state park system candlestick point\n",
            "['there is only one park managed by the california state park system candlestick point', 'there is one state park in san francisco']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What does a polar bear's fur provide?\n",
            "Predicated answer: a polar bear s fur provides camouflage and insulation\n",
            "['it provides the animal with effective camouflage', \"a polar bear's fur provides camouflage and insulation\"]\n",
            "Bleu score: 0.9506885335787997\n",
            "\n",
            "Original question: Do turtles lay eggs underwater?\n",
            "Predicated answer: no\n",
            "['no', 'no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are cougars larger than jaguars?\n",
            "Predicated answer: no\n",
            "['cougars are not larger than jaguars', 'no']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When did Roosevelt die?\n",
            "Predicated answer: on january 6 1919 roosevelt died in his sleep\n",
            "['on january 6 1919 roosevelt died in his sleep', 'on january 6 1919 roosevelt died in his sleep']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is the Giant Panda a terrestrial animal?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What happened in 1865?\n",
            "Predicated answer: he accepted the surrender of robert e lee\n",
            "['he accepted the surrender of robert e lee']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where is the bust of Queen Nefertiti?\n",
            "Predicated answer: the bust of queen nefertiti is in the altes museum\n",
            "['the bust of queen nefertiti is in the altes museum']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What are dark leopards known as colloquially?\n",
            "Predicated answer: black panthers\n",
            "['black panthers', 'black panthers']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where was the League of Nations created?\n",
            "Predicated answer: paris\n",
            "['paris', 'paris']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Did he not cast his ballot for John M. Palmer , the presidential candidate of the National Democratic Party , or Gold Democrats , a short-lived party that supported a gold standard , low tariffs , and limited government ?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was Lombardy under Napoleon's rule in 1800?\n",
            "Predicated answer: no\n",
            "['yes', 'yes']\n",
            "Bleu score: 0\n",
            "\n",
            "Original question: What is the only variety of modern Arabic that has acquired official language status?\n",
            "Predicated answer: maltese\n",
            "['maltese', 'maltese']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is the violin cello a bowed string instrument?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Do kangaroos eat plants?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is polar bear a carnivore?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is the sustain pedal called?\n",
            "Predicated answer: the pedal\n",
            "['the pedal', 'damper pedal']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Felis pardus was what?\n",
            "Predicated answer: one of the many species described in linnaeus s 18thcentury work systema naturae\n",
            "[\"one of the many species described in linnaeus's 18thcentury work systema naturae\"]\n",
            "Bleu score: 0.9678317907712601\n",
            "\n",
            "Original question: What is the second main orchestral use of cymbals?\n",
            "Predicated answer: the suspended cymbal\n",
            "['the suspended cymbal is the second main orchestral use of symbals', 'the suspended cymbal', 'the suspended cymbal', 'the suspended cymbal']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is it true that indonesia has vast areas of wilderness?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Do older pianos have more keys than modern pianos?\n",
            "Predicated answer: no\n",
            "['no', 'many older pianos only have 85 keys']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where is the leopard distributed?\n",
            "Predicated answer: southern eurasia and africa\n",
            "['southern eurasia and africa', 'southern eurasia and africa from korea to south africa and spain']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was the SI unit of charge named after Charles-Augustin de Coulomb?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes the si unit of charge the coulomb was named after him']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How many townships are in Ottawa?\n",
            "Predicated answer: eleven\n",
            "['eleven', 'eleven']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where was the oldest flute ever discovered found?\n",
            "Predicated answer: germany\n",
            "['germany', 'various parts of germany']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What's the main highway in Ottawa?\n",
            "Predicated answer: hassan massoudy\n",
            "['highway 417 the queensway', 'provinical highway 417']\n",
            "Bleu score: 0.5519084639638498\n",
            "\n",
            "Original question: In what year were the \"Games of the XV Olympiad\" held?\n",
            "Predicated answer: 1952\n",
            "['1952', '1952']\n",
            "Bleu score: 1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original question: Where is smoked eel considered a delicacy?\n",
            "Predicated answer: northern germany the netherlands denmark sweden\n",
            "['northern germany the netherlands denmark sweden', 'smoked eel is considered a delicacy in northern germany the netherlands denmark and sweden']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is Ottawa's junior ice hockey team?\n",
            "Predicated answer: the middle states has the west is the center point of the center of saint lawrence river\n",
            "[\"the ottawa 67's\"]\n",
            "Bleu score: 0.040050763315923193\n",
            "\n",
            "Original question: Was Ford active about Vietnamese affairs?\n",
            "Predicated answer: yes\n",
            "['no', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: How many seasons does Kuala Lumpur experience?\n",
            "Predicated answer: 1\n",
            "['1']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What happened in 1764?\n",
            "Predicated answer: adams married abigail smith\n",
            "['adams married abigail smith']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was Grover Cleveland elected Sheriff of Erie County, New York?\n",
            "Predicated answer: yes\n",
            "['yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: When did his father die?\n",
            "Predicated answer: his father died in 1651\n",
            "['1651', 'his father died in 1651']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Name an animal that is growing in number due to recent conservation efforts\n",
            "Predicated answer: golden eagle\n",
            "['golden eagle brown bear or eurasian lynx change imperative to interrogative', 'golden eagle']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is James Watt most famous for?\n",
            "Predicated answer: steam engine\n",
            "['steam engine']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: What is the name of the largest church in Montreal?\n",
            "Predicated answer: the largest church in montreal is named saint joseph s oratory\n",
            "[\"the largest church in montreal is named saint joseph's oratory\", \"saint joseph's oratory is the largest church in montreal\"]\n",
            "Bleu score: 0.9581282631934457\n",
            "\n",
            "Original question: What was Ottawa's name in 1850?\n",
            "Predicated answer: bytown\n",
            "['bytown', 'bytown']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Are beetles endopterygotes?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where do Giant Pandas live?\n",
            "Predicated answer: a few mountain ranges in central china\n",
            "['a few mountain ranges in central china', 'sichuan province shaanxi and gansu provinces']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Is the leopard one of the four 'big cats'?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Was Calvin Coolidge born in Plymouth, Windsor County, Vermont?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Does a polar bear live in the Arctic?\n",
            "Predicated answer: yes\n",
            "['yes', 'yes']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Original question: Where is the James Watt Memorial College?\n",
            "Predicated answer: in greenock\n",
            "['in greenock', 'the james watt memorial  is in greenock']\n",
            "Bleu score: 1.0\n",
            "\n",
            "Bleu average = 0.9472225587930803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input('Ask me something, or enter \\'end\\' to stop: ')\n",
        "    if question == 'end':\n",
        "        break\n",
        "    states_values = enc_model.predict(str_to_tokens(question))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "\n",
        "    decoded_translation = ''\n",
        "    while True:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'stop':\n",
        "                    decoded_translation += ' {}'.format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'stop' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            break\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "metadata": {
        "id": "KAsbo2TRkAsh",
        "outputId": "7a858020-482b-43a6-c043-47a90618e922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask me something, or enter 'end' to stop:  What is the name of the largest church in Montreal?\n",
            " the largest church in montreal is named saint joseph s oratory\n",
            "Ask me something, or enter 'end' to stop:  What is the name of the church in Montreal?\n",
            " the largest church in montreal is named saint joseph s oratory\n",
            "Ask me something, or enter 'end' to stop: Name of churn in Montreal?\n",
            " the spanish\n",
            "Ask me something, or enter 'end' to stop: What is a name of a church in Montreal?\n",
            " a female turtle\n",
            "Ask me something, or enter 'end' to stop: What is the name of the largest in Montreal?\n",
            " the largest church in montreal is named saint joseph s oratory\n",
            "Ask me something, or enter 'end' to stop: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ny-x6HP6wrg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}